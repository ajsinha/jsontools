"""

Copyright (C) 2025-2030, All Rights Reserved
Ashutosh Sinha
Email: ajsinha@gmail.com

LEGAL NOTICE:
This software is proprietary and confidential. Unauthorized copying,
distribution, modification, or use is strictly prohibited without
explicit written permission from the copyright holder.

Patent Pending: Certain implementations may be subject to patent applications.

Code Generator - Generate Python source code from JSON Schema.

Features:
- Dataclass generation with full type hints
- Multiple code styles (dataclass, attrs, plain)
- Automatic import management
- Docstring generation
- Validation method generation
"""

import re
from typing import Any, Dict, List, Optional, Set, Tuple
from datetime import datetime

from ..core.reference_resolver import ReferenceResolver
from ..core.type_mapper import TypeMapper, TypeMapping
from ..core.schema_parser import SchemaParser


class CodeGenerator:
    """
    Generates Python source code from JSON Schema.
    
    Produces clean, well-formatted Python code with proper imports,
    type hints, docstrings, and serialization methods.
    """
    
    def __init__(
        self,
        schema: Dict[str, Any],
        resolver: Optional[ReferenceResolver] = None,
        type_mapper: Optional[TypeMapper] = None,
        root_class_name: str = "Root",
        style: str = "dataclass",
        include_validators: bool = True,
        include_docstrings: bool = True,
        all_fields_optional: bool = False,
    ):
        """
        Initialize the code generator.
        
        Args:
            schema: The JSON Schema
            resolver: Reference resolver
            type_mapper: Type mapper
            root_class_name: Name for the root class
            style: Code style ("dataclass", "attrs", "plain")
            include_validators: Whether to include validation methods
            include_docstrings: Whether to include docstrings
            all_fields_optional: If True, all fields get default None (allows empty constructor)
        """
        self.schema = schema
        self.resolver = resolver or ReferenceResolver(schema)
        self.type_mapper = type_mapper or TypeMapper()
        self.root_class_name = root_class_name
        self.style = style
        self.include_validators = include_validators
        self.include_docstrings = include_docstrings
        self.all_fields_optional = all_fields_optional
        
        # Get resolved schema
        self.resolved_schema = self.resolver.resolve_all()
        
        # Extract definitions
        self.definitions = self.resolved_schema.get(
            "definitions",
            self.resolved_schema.get("$defs", {})
        )
        
        # Track generated class names
        self._generated_classes: Set[str] = set()
        
        # Track required imports
        self._imports: Set[str] = set()
    
    def generate(self) -> str:
        """
        Generate Python source code.
        
        Returns:
            Complete Python module as a string
        """
        lines = []
        
        # Generate classes
        class_codes = []
        
        # Generate definition classes first
        for def_name, def_schema in self.definitions.items():
            if def_schema.get("type") == "object" or "properties" in def_schema:
                class_code = self._generate_class(def_name, def_schema)
                class_codes.append(class_code)
        
        # Generate root class
        if self.resolved_schema.get("type") == "object" or "properties" in self.resolved_schema:
            class_code = self._generate_class(self.root_class_name, self.resolved_schema)
            class_codes.append(class_code)
        
        # Build complete module
        lines.append(self._generate_header())
        lines.append("")
        lines.append(self._generate_imports())
        lines.append("")
        lines.append("")
        
        # Add ValidationResult class first
        lines.append(self._generate_validation_result_class())
        lines.append("")
        
        # Add classes
        for class_code in class_codes:
            lines.append(class_code)
            lines.append("")
        
        return "\n".join(lines)
    
    def _generate_header(self) -> str:
        """Generate module docstring."""
        return f'''"""
Auto-generated Python classes from JSON Schema.

Generated by JsonSchemaCodeGen on {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

This module contains dataclasses generated from JSON Schema definitions.
Each class includes:
- Type hints for all properties
- Serialization methods (to_dict, to_json)
- Deserialization class methods (from_dict, from_json)
- Validation method to check required fields and enum values
"""'''
    
    def _generate_validation_result_class(self) -> str:
        """Generate the ValidationResult class."""
        return '''@dataclass
class ValidationResult:
    """Result of validation containing status and any errors."""
    is_valid: bool
    errors: List[str] = field(default_factory=list)
    
    def __str__(self) -> str:
        if self.is_valid:
            return "Valid"
        return f"Invalid: {'; '.join(self.errors)}"
    
    def __bool__(self) -> bool:
        return self.is_valid'''
    
    def _generate_imports(self) -> str:
        """Generate import statements."""
        imports = [
            "from __future__ import annotations",
            "",
            "import json",
            "from dataclasses import dataclass, field, asdict",
            "from typing import Any, Dict, List, Optional, Union",
            "from datetime import datetime, date",
        ]
        
        # Add collected imports
        for imp in sorted(self._imports):
            if imp not in "\n".join(imports):
                imports.append(imp)
        
        return "\n".join(imports)
    
    def _generate_class(
        self,
        class_name: str,
        schema: Dict[str, Any],
    ) -> str:
        """Generate code for a single class."""
        if class_name in self._generated_classes:
            return ""
        
        self._generated_classes.add(class_name)
        
        lines = []
        
        # Class decorator
        if self.style == "dataclass":
            lines.append("@dataclass")
        
        # Class definition
        lines.append(f"class {class_name}:")
        
        # Docstring
        if self.include_docstrings:
            description = schema.get("description", f"Generated class for {class_name}.")
            lines.append(f'    """{description}"""')
            lines.append("")
        
        # Get properties
        properties = schema.get("properties", {})
        required = set(schema.get("required", []))
        
        if not properties:
            lines.append("    pass")
            return "\n".join(lines)
        
        # Separate required and optional fields
        required_fields = []
        optional_fields = []
        
        for prop_name, prop_schema in properties.items():
            safe_name = self._to_safe_name(prop_name)
            mapping = self.type_mapper.map_schema(prop_schema, prop_name)
            
            # Collect imports
            if mapping.import_statement:
                self._imports.add(mapping.import_statement)
            
            field_info = {
                "name": safe_name,
                "original_name": prop_name,
                "type_hint": self._get_type_hint(mapping, prop_schema),
                "schema": prop_schema,
                "mapping": mapping,
            }
            
            if prop_name in required:
                required_fields.append(field_info)
            else:
                optional_fields.append(field_info)
        
        # Property mapping for JSON serialization - use a class variable (ClassVar)
        # instead of a dataclass field to avoid mutable default issues
        lines.append("    # Property name mapping for JSON serialization")
        mapping_items = []
        for f in required_fields + optional_fields:
            mapping_items.append(f'            "{f["name"]}": "{f["original_name"]}"')
        
        # Use a method to get the mapping instead of a class field
        lines.append("    @classmethod")
        lines.append("    def _get_json_mapping(cls) -> Dict[str, str]:")
        lines.append("        return {")
        lines.append(",\n".join(mapping_items))
        lines.append("        }")
        lines.append("")
        
        # When all_fields_optional is True, treat all fields as optional
        if self.all_fields_optional:
            # All fields get default values
            all_fields = required_fields + optional_fields
            for field_info in all_fields:
                type_hint = field_info["type_hint"]
                # Wrap in Optional if not already
                if not type_hint.startswith("Optional") and not type_hint.startswith("List[") and not type_hint.startswith("Dict["):
                    type_hint = f"Optional[{type_hint}]"
                
                # Determine default value
                default = self._get_default_value(field_info["mapping"])
                
                comment = self._get_field_comment(field_info["schema"])
                if comment:
                    lines.append(f"    {field_info['name']}: {type_hint} = {default}  # {comment}")
                else:
                    lines.append(f"    {field_info['name']}: {type_hint} = {default}")
        else:
            # Generate required fields (no defaults)
            for field_info in required_fields:
                comment = self._get_field_comment(field_info["schema"])
                if comment:
                    lines.append(f"    {field_info['name']}: {field_info['type_hint']}  # {comment}")
                else:
                    lines.append(f"    {field_info['name']}: {field_info['type_hint']}")
            
            # Generate optional fields (with defaults)
            for field_info in optional_fields:
                type_hint = field_info["type_hint"]
                if not type_hint.startswith("Optional"):
                    type_hint = f"Optional[{type_hint}]"
                
                # Determine default value
                default = self._get_default_value(field_info["mapping"])
                
                comment = self._get_field_comment(field_info["schema"])
                if comment:
                    lines.append(f"    {field_info['name']}: {type_hint} = {default}  # {comment}")
                else:
                    lines.append(f"    {field_info['name']}: {type_hint} = {default}")
        
        # Add methods - pass required fields and all fields for validation
        lines.append("")
        all_fields = required_fields + optional_fields
        lines.extend(self._generate_methods(class_name, required_fields, all_fields))
        
        return "\n".join(lines)
    
    def _get_type_hint(
        self,
        mapping: TypeMapping,
        schema: Dict[str, Any],
    ) -> str:
        """Get the type hint string."""
        # Check for $ref to other definitions
        if "$ref" in schema:
            ref = schema["$ref"]
            class_name = ref.split("/")[-1]
            return f'"{class_name}"'
        
        if mapping.is_custom_class and mapping.custom_class_name:
            return f'"{mapping.custom_class_name}"'
        
        if mapping.is_list:
            items = schema.get("items", {})
            if "$ref" in items:
                item_class = items["$ref"].split("/")[-1]
                return f'List["{item_class}"]'
            elif mapping.list_item_type:
                return f"List[{mapping.list_item_type.type_hint}]"
            return "List[Any]"
        
        if mapping.is_dict:
            return "Dict[str, Any]"
        
        return mapping.type_hint
    
    def _get_default_value(self, mapping: TypeMapping) -> str:
        """Get the default value representation for a field."""
        if mapping.is_list:
            return "field(default_factory=list)"
        if mapping.is_dict:
            return "field(default_factory=dict)"
        if mapping.default_value:
            return mapping.default_value
        return "None"
    
    def _get_field_comment(self, schema: Dict[str, Any]) -> str:
        """Get a comment for a field from schema description."""
        description = schema.get("description", "")
        if description:
            # Truncate long descriptions
            if len(description) > 60:
                description = description[:57] + "..."
            return description
        return ""
    
    def _generate_methods(self, class_name: str, required_fields: List[Dict] = None, all_fields: List[Dict] = None) -> List[str]:
        """Generate serialization and validation methods."""
        methods = []
        required_fields = required_fields or []
        all_fields = all_fields or []
        
        # to_dict method
        methods.extend([
            "    def to_dict(self) -> Dict[str, Any]:",
            '        """Convert to dictionary with original JSON property names."""',
            "        result = {}",
            "        for py_name, json_name in self._get_json_mapping().items():",
            "            value = getattr(self, py_name, None)",
            "            if value is not None:",
            "                if hasattr(value, 'to_dict'):",
            "                    result[json_name] = value.to_dict()",
            "                elif isinstance(value, list):",
            "                    result[json_name] = [",
            "                        item.to_dict() if hasattr(item, 'to_dict') else item",
            "                        for item in value",
            "                    ]",
            "                elif isinstance(value, (datetime, date)):",
            "                    result[json_name] = value.isoformat()",
            "                else:",
            "                    result[json_name] = value",
            "        return result",
            "",
        ])
        
        # to_json method
        methods.extend([
            "    def to_json(self, indent: int = 2) -> str:",
            '        """Serialize to JSON string."""',
            "        return json.dumps(self.to_dict(), indent=indent, default=str)",
            "",
        ])
        
        # from_dict class method
        methods.extend([
            "    @classmethod",
            f"    def from_dict(cls, data: Dict[str, Any]) -> '{class_name}':",
            '        """Create instance from dictionary."""',
            "        reverse_mapping = {v: k for k, v in cls._get_json_mapping().items()}",
            "        kwargs = {}",
            "        for json_name, value in data.items():",
            "            py_name = reverse_mapping.get(json_name, json_name)",
            "            if py_name in cls.__annotations__:",
            "                kwargs[py_name] = value",
            "        return cls(**kwargs)",
            "",
        ])
        
        # from_json class method
        methods.extend([
            "    @classmethod",
            f"    def from_json(cls, json_str: str) -> '{class_name}':",
            '        """Create instance from JSON string."""',
            "        return cls.from_dict(json.loads(json_str))",
            "",
        ])
        
        # Generate _get_required_fields method
        required_field_names = [f['name'] for f in required_fields]
        methods.extend([
            "    @classmethod",
            "    def _get_required_fields(cls) -> List[str]:",
            '        """Get list of required field names."""',
            f"        return {required_field_names}",
            "",
        ])
        
        # Generate _get_enum_constraints method - collect enum info
        enum_constraints = {}
        for field_info in all_fields:
            schema = field_info.get("schema", {})
            if "enum" in schema:
                enum_constraints[field_info["name"]] = schema["enum"]
        
        methods.extend([
            "    @classmethod",
            "    def _get_enum_constraints(cls) -> Dict[str, List[Any]]:",
            '        """Get enum constraints for fields."""',
            f"        return {repr(enum_constraints)}",
            "",
        ])
        
        # Generate validate method
        methods.extend([
            "    def validate(self) -> 'ValidationResult':",
            '        """',
            '        Validate that all required fields are populated and enum values are valid.',
            '        ',
            '        Returns:',
            '            ValidationResult with is_valid flag and list of errors',
            '        """',
            "        errors = []",
            "        ",
            "        # Check required fields",
            "        for field_name in self._get_required_fields():",
            "            value = getattr(self, field_name, None)",
            "            if value is None:",
            "                errors.append(f\"Required field '{field_name}' is not set\")",
            "        ",
            "        # Check enum constraints",
            "        for field_name, valid_values in self._get_enum_constraints().items():",
            "            value = getattr(self, field_name, None)",
            "            if value is not None and value not in valid_values:",
            "                errors.append(f\"Field '{field_name}' has invalid value '{value}'. Must be one of: {valid_values}\")",
            "        ",
            "        return ValidationResult(is_valid=len(errors) == 0, errors=errors)",
        ])
        
        return methods
    
    def _to_safe_name(self, name: str) -> str:
        """Convert a name to a valid Python identifier."""
        safe = name.replace("-", "_").replace(" ", "_").replace(".", "_")
        safe = safe.replace("@", "_at_").replace("#", "_hash_")
        
        if safe and safe[0].isdigit():
            safe = "_" + safe
        
        # Python keywords and built-ins that conflict with dataclass usage
        keywords = {
            "class", "def", "return", "import", "from", "for", "while",
            "if", "else", "elif", "try", "except", "finally", "with",
            "as", "is", "in", "not", "and", "or", "True", "False", "None",
            # Dataclass-specific conflicts
            "field", "dataclass", "asdict", "astuple", "fields",
            # Common conflicts
            "type", "id", "list", "dict", "set", "str", "int", "float", "bool",
        }
        if safe in keywords:
            safe = safe + "_"
        
        return safe


def generate_code(
    schema: Dict[str, Any],
    root_class_name: str = "Root",
    style: str = "dataclass",
    **kwargs,
) -> str:
    """
    Convenience function to generate Python code from a schema.
    
    Args:
        schema: The JSON Schema
        root_class_name: Name for the root class
        style: Code style ("dataclass", "attrs", "plain")
        **kwargs: Additional arguments for CodeGenerator
        
    Returns:
        Python source code as string
    """
    generator = CodeGenerator(
        schema,
        root_class_name=root_class_name,
        style=style,
        **kwargs,
    )
    return generator.generate()
